{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCiApndWSDxv",
        "outputId": "a08c6696-8743-439e-ee54-af0f7c346a90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.11.0)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.11/dist-packages (0.13.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.5.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.14.0)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.1)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile) (1.17.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile) (2.22)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.3.8)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (2.32.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.6.15)\n"
          ]
        }
      ],
      "source": [
        "!pip install librosa soundfile numpy pandas scikit-learn matplotlib seaborn tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import soundfile as sf\n",
        "import librosa\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set(style=\"whitegrid\")"
      ],
      "metadata": {
        "id": "2yZoBkVZSEjk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"kam001/audio-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYJ22ombSOMZ",
        "outputId": "40b50b8a-26cc-4eeb-c55c-4ff4ffbe120a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /kaggle/input/audio-dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Map RAVDESS filename codes to emotion labels\n",
        "emotion_map = {\n",
        "    '01':'neutral','02':'calm','03':'happy','04':'sad',\n",
        "    '05':'angry','06':'fearful','07':'disgust','08':'surprise'\n",
        "}\n",
        "\n",
        "def load_metadata(base_dir):\n",
        "    paths, labels = [], []\n",
        "    for root, _, files in os.walk(base_dir):\n",
        "        for f in files:\n",
        "            if not f.endswith('.wav'):\n",
        "                continue\n",
        "            parts = f.split('-')\n",
        "            # modality=03 (audio-only), channel=01 (speech)\n",
        "            if len(parts) >= 3 and parts[0]=='03' and parts[1]=='01':\n",
        "                paths.append(os.path.join(root, f))\n",
        "                labels.append(emotion_map.get(parts[2], 'unknown'))\n",
        "    return pd.DataFrame({'path': paths, 'emotion': labels})\n",
        "\n",
        "data_dir = '/kaggle/input/audio-dataset'\n",
        "df = load_metadata(data_dir)\n",
        "\n",
        "print(f\"Loaded {len(df)} files\")\n",
        "print(df.emotion.value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_o4GA2HSKCU",
        "outputId": "718b3b12-cd22-4a94-b3c6-b406956fdb52"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 1440 files\n",
            "emotion\n",
            "surprise    192\n",
            "disgust     192\n",
            "fearful     192\n",
            "sad         192\n",
            "happy       192\n",
            "calm        192\n",
            "angry       192\n",
            "neutral      96\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# extract_feature.py\n",
        "\n",
        "import librosa\n",
        "import numpy as np\n",
        "import soundfile as sf\n",
        "\n",
        "def extract_feature(file_path, n_mels=128, sr=16000, duration=3):\n",
        "    y, orig_sr = sf.read(file_path, dtype='float32')\n",
        "\n",
        "    if y.ndim > 1:\n",
        "        y = np.mean(y, axis=1)\n",
        "\n",
        "    if orig_sr != sr:\n",
        "        y = librosa.resample(y, orig_sr=orig_sr, target_sr=sr)\n",
        "\n",
        "    # Pad or trim to fixed duration\n",
        "    target_len = sr * duration\n",
        "    if len(y) < target_len:\n",
        "        y = np.pad(y, (0, target_len - len(y)))\n",
        "    else:\n",
        "        y = y[:target_len]\n",
        "\n",
        "    # Log-mel spectrogram\n",
        "    mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels)\n",
        "    log_mel = librosa.power_to_db(mel_spec, ref=np.max)\n",
        "    return log_mel  # shape: (128, T)\n",
        "\n"
      ],
      "metadata": {
        "id": "5GcXzOApSwNA"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "\n",
        "feature_list = []\n",
        "for fp in tqdm(df.path, desc=\"Extracting features\"):\n",
        "    feature_list.append(extract_feature(fp))  # Each is (128, T)\n",
        "\n",
        "# Resize all to fixed shape (e.g. 128x128)\n",
        "X = np.array([librosa.util.fix_length(f, size=128, axis=1) for f in feature_list])  # Shape: (N, 128, 128)\n",
        "y = df.emotion.values\n",
        "\n",
        "print(\"Feature matrix shape:\", X.shape)  # e.g. (1440, 128, 128)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FtnZySDES6bN",
        "outputId": "ca23f2cf-84eb-4c57-ff3c-c29247e09a9e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting features: 100%|██████████| 1440/1440 [00:47<00:00, 30.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature matrix shape: (1440, 128, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# After this...\n",
        "feature_list = []\n",
        "for fp in tqdm(df.path, desc=\"Extracting features\"):\n",
        "    feature_list.append(extract_feature(fp))  # Returns (128, T)\n",
        "\n",
        "# Resize all to (128, 128)\n",
        "X = np.array([librosa.util.fix_length(f, size=128, axis=1) for f in feature_list])  # (N, 128, 128)\n",
        "y = df.emotion.values  # e.g., encoded labels\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YpFIi82vcgcw",
        "outputId": "205c3e9f-1dca-4e62-890a-058e75a9b53d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting features: 100%|██████████| 1440/1440 [00:16<00:00, 85.61it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "\n",
        "# Save label encoder for inference\n",
        "import joblib\n",
        "joblib.dump(le, \"label_encoder.pkl\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eciRNO_QczBE",
        "outputId": "4329f2e7-d6b7-423d-932b-acfe712660a2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['label_encoder.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y_encoded, test_size=0.2, stratify=y_encoded, random_state=42\n",
        ")\n"
      ],
      "metadata": {
        "id": "kadaNM1NcrK6"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import torch\n",
        "\n",
        "class SpectrogramDataset(Dataset):\n",
        "    def __init__(self, X, y, transform=None):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = self.X[idx]\n",
        "        img = Image.fromarray((img - img.min()) / (img.max() - img.min()) * 255).convert(\"L\")\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, self.y[idx]\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5], [0.5])\n",
        "])\n",
        "\n",
        "train_ds = SpectrogramDataset(X_train, y_train, transform)\n",
        "test_ds  = SpectrogramDataset(X_test, y_test, transform)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
        "test_loader  = DataLoader(test_ds, batch_size=32)\n"
      ],
      "metadata": {
        "id": "ycEmk8L6crNf"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = models.resnet18(pretrained=False)\n",
        "model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)  # 1 channel\n",
        "model.fc = nn.Linear(model.fc.in_features, len(le.classes_))\n",
        "model = model.to(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6l9JqqincrP1",
        "outputId": "4f19f842-4ada-4b98-e9fc-0f93fbb46912"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(100):\n",
        "    model.train()\n",
        "    running_loss = 0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}: Loss = {running_loss:.10f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GAGViv3yc_f4",
        "outputId": "a9207ec3-3f98-4a2f-8a75-fb8f40cff86e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Loss = 65.4746266603\n",
            "Epoch 2: Loss = 49.8251084089\n",
            "Epoch 3: Loss = 42.2513065338\n",
            "Epoch 4: Loss = 37.3216333389\n",
            "Epoch 5: Loss = 31.5409514904\n",
            "Epoch 6: Loss = 25.7720549703\n",
            "Epoch 7: Loss = 19.0384627283\n",
            "Epoch 8: Loss = 16.7856324613\n",
            "Epoch 9: Loss = 10.9953543842\n",
            "Epoch 10: Loss = 13.4594138116\n",
            "Epoch 11: Loss = 10.0810331777\n",
            "Epoch 12: Loss = 8.4653440863\n",
            "Epoch 13: Loss = 5.2155143358\n",
            "Epoch 14: Loss = 2.6345114764\n",
            "Epoch 15: Loss = 3.3167638732\n",
            "Epoch 16: Loss = 4.9766954705\n",
            "Epoch 17: Loss = 4.0502650440\n",
            "Epoch 18: Loss = 4.8093749657\n",
            "Epoch 19: Loss = 5.0013228580\n",
            "Epoch 20: Loss = 3.6546622915\n",
            "Epoch 21: Loss = 4.5311867953\n",
            "Epoch 22: Loss = 3.6865304522\n",
            "Epoch 23: Loss = 2.8422668120\n",
            "Epoch 24: Loss = 1.3086641373\n",
            "Epoch 25: Loss = 1.2073666952\n",
            "Epoch 26: Loss = 0.8179105308\n",
            "Epoch 27: Loss = 0.3424441983\n",
            "Epoch 28: Loss = 0.1878867992\n",
            "Epoch 29: Loss = 0.0986985708\n",
            "Epoch 30: Loss = 0.0504640642\n",
            "Epoch 31: Loss = 0.0289399986\n",
            "Epoch 32: Loss = 0.0317973650\n",
            "Epoch 33: Loss = 0.0230790770\n",
            "Epoch 34: Loss = 0.0189694324\n",
            "Epoch 35: Loss = 0.0226861495\n",
            "Epoch 36: Loss = 0.0218996390\n",
            "Epoch 37: Loss = 0.0202504042\n",
            "Epoch 38: Loss = 0.0151966270\n",
            "Epoch 39: Loss = 0.0098798647\n",
            "Epoch 40: Loss = 0.0128159160\n",
            "Epoch 41: Loss = 0.0143037144\n",
            "Epoch 42: Loss = 0.0085622278\n",
            "Epoch 43: Loss = 0.0143690481\n",
            "Epoch 44: Loss = 0.0141695985\n",
            "Epoch 45: Loss = 0.0110200383\n",
            "Epoch 46: Loss = 0.0062197837\n",
            "Epoch 47: Loss = 0.0099437066\n",
            "Epoch 48: Loss = 0.0059285307\n",
            "Epoch 49: Loss = 0.0077529585\n",
            "Epoch 50: Loss = 0.0058673552\n",
            "Epoch 51: Loss = 0.0072142219\n",
            "Epoch 52: Loss = 0.0069027910\n",
            "Epoch 53: Loss = 0.0058144196\n",
            "Epoch 54: Loss = 0.0063363816\n",
            "Epoch 55: Loss = 0.0077107547\n",
            "Epoch 56: Loss = 0.0037119099\n",
            "Epoch 57: Loss = 0.0037043739\n",
            "Epoch 58: Loss = 0.0040488133\n",
            "Epoch 59: Loss = 0.0077664578\n",
            "Epoch 60: Loss = 0.0033947658\n",
            "Epoch 61: Loss = 0.0035186632\n",
            "Epoch 62: Loss = 0.0030531163\n",
            "Epoch 63: Loss = 0.0049971855\n",
            "Epoch 64: Loss = 0.0029939615\n",
            "Epoch 65: Loss = 0.0038342075\n",
            "Epoch 66: Loss = 0.0031917916\n",
            "Epoch 67: Loss = 0.0063723975\n",
            "Epoch 68: Loss = 0.0032010004\n",
            "Epoch 69: Loss = 0.0036268065\n",
            "Epoch 70: Loss = 0.0033699988\n",
            "Epoch 71: Loss = 0.0021693724\n",
            "Epoch 72: Loss = 0.0024549362\n",
            "Epoch 73: Loss = 0.0019395156\n",
            "Epoch 74: Loss = 0.0032268164\n",
            "Epoch 75: Loss = 0.0058580419\n",
            "Epoch 76: Loss = 0.0035726504\n",
            "Epoch 77: Loss = 0.0026338983\n",
            "Epoch 78: Loss = 0.0033201106\n",
            "Epoch 79: Loss = 0.0020929087\n",
            "Epoch 80: Loss = 0.0027834093\n",
            "Epoch 81: Loss = 0.0018481669\n",
            "Epoch 82: Loss = 0.0015651582\n",
            "Epoch 83: Loss = 0.0019249079\n",
            "Epoch 84: Loss = 0.0018038826\n",
            "Epoch 85: Loss = 0.0015259071\n",
            "Epoch 86: Loss = 0.0027372425\n",
            "Epoch 87: Loss = 0.0014868872\n",
            "Epoch 88: Loss = 0.0014676317\n",
            "Epoch 89: Loss = 0.0022940310\n",
            "Epoch 90: Loss = 0.0017013104\n",
            "Epoch 91: Loss = 0.0017889432\n",
            "Epoch 92: Loss = 0.0014609651\n",
            "Epoch 93: Loss = 0.0016838855\n",
            "Epoch 94: Loss = 0.0018830226\n",
            "Epoch 95: Loss = 0.0015182480\n",
            "Epoch 96: Loss = 0.0015464515\n",
            "Epoch 97: Loss = 0.0013358896\n",
            "Epoch 98: Loss = 0.0011998336\n",
            "Epoch 99: Loss = 0.0019242505\n",
            "Epoch 100: Loss = 0.0020282958\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "\n",
        "# Convert to float16\n",
        "model_fp16 = model.half()  # Convert model to float16\n",
        "\n",
        "# Save\n",
        "torch.save(model_fp16.state_dict(), \"resnet18_emotion_fp16.pt\")\n",
        "\n",
        "# Check file size\n",
        "size_mb = os.path.getsize(\"resnet18_emotion_fp16.pt\") / (1024 ** 2)\n",
        "print(f\"Float16 model saved! Size: {size_mb:.2f} MB\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebVzph6VdECB",
        "outputId": "db4cc1fb-c1d8-448e-8be4-545d6bd92832"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Float16 model saved! Size: 21.37 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Convert model to float16\n",
        "model = model.half()\n",
        "model.eval()\n",
        "\n",
        "all_preds, all_labels = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs = inputs.to(device).half()  # convert input to float16\n",
        "        outputs = model(inputs)\n",
        "        preds = outputs.argmax(dim=1).cpu().numpy()\n",
        "        all_preds.extend(preds)\n",
        "        all_labels.extend(labels.numpy())\n",
        "\n",
        "print(classification_report(all_labels, all_preds, target_names=le.classes_))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCzq5dmQdH1v",
        "outputId": "188035d8-6b41-4de7-89d2-823d6c8b8258"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.85      0.89      0.87        38\n",
            "        calm       0.88      0.95      0.91        38\n",
            "     disgust       0.92      0.92      0.92        38\n",
            "     fearful       0.71      0.90      0.80        39\n",
            "       happy       0.61      0.56      0.59        39\n",
            "     neutral       0.73      0.58      0.65        19\n",
            "         sad       0.76      0.74      0.75        38\n",
            "    surprise       0.94      0.77      0.85        39\n",
            "\n",
            "    accuracy                           0.80       288\n",
            "   macro avg       0.80      0.79      0.79       288\n",
            "weighted avg       0.80      0.80      0.80       288\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZoY7s4YquJCg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}